{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os import walk\n",
    "import sys\n",
    "import os.path\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder 안에 파일 이름 저장\n",
    "mp3_list =[]\n",
    "folder = [j for i,j,k in walk(r'../fma_medium')][0]\n",
    "temp = [mp3_list.extend(k) for i,j,k in walk(r'../fma_medium')]\n",
    "music_list = [i[:10] for i in mp3_list[2:]]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# mp3 -> wav\n",
    "cnt=0\n",
    "cntt=0\n",
    "for i in folder:\n",
    "    cnt+=1\n",
    "    mp3_list =[]\n",
    "    temp = [mp3_list.extend(k) for i,j,k in walk(r'../fma_medium/'+i+'/')]\n",
    "    for j in mp3_list[2:]:\n",
    "        cntt+=1\n",
    "        thisFile = \"../fma_medium/\"+i+'/'+j\n",
    "        base = os.path.splitext(thisFile)[0]\n",
    "        os.rename(thisFile, base + \".wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Genres =  163\n"
     ]
    }
   ],
   "source": [
    "genreslist = pd.read_csv('./fma_metadata/genres.csv')\n",
    "genreslist['title'] = [i.lower() for i in genreslist['title']]\n",
    "print('#Genres = ',len(genreslist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre_id</th>\n",
       "      <th>#tracks</th>\n",
       "      <th>parent</th>\n",
       "      <th>title</th>\n",
       "      <th>top_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>539</td>\n",
       "      <td>638</td>\n",
       "      <td>21</td>\n",
       "      <td>rap</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     genre_id  #tracks  parent title  top_level\n",
       "142       539      638      21   rap         21"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genreslist[genreslist['title']=='rap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "genredict = {k:v for v,k in zip(genreslist['title'],genreslist['genre_id'])}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tracklist = pd.read_csv('./fma_metadata/tracks.csv')\n",
    "tracklist = tracklist.drop([0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dataDF = pd.concat([tracklist['Unnamed: 0'],tracklist['track.8']],axis=1)\n",
    "dataDF.columns = ['Track_ID', 'Genres']\n",
    "dataDF = dataDF.drop([1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "len(dataDF)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#가지고 있는 음악 파일 리스트 만들기\n",
    "# music_list = [int(i[:6]) for i in music_list]\n",
    "print('#total = ',len(dataDF))\n",
    "for i,j in enumerate(dataDF['Track_ID']):\n",
    "    if int(j) not in music_list:\n",
    "        dataDF = dataDF.drop([i])\n",
    "print('#song in file = ',len(dataDF))\n",
    "import pickle\n",
    "with open('FMA_M_list.pickle', 'wb') as f:\n",
    "    pickle.dump(dataDF, f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dataDF = pd.read_pickle('FMA_M_list.pickle')\n",
    "dataDF = dataDF.reset_index()\n",
    "for i,j in enumerate(dataDF['Genres']):\n",
    "    if j == '[]':\n",
    "        dataDF = dataDF.drop(i)\n",
    "del dataDF['index']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i in range(len(dataDF['Genres'])):\n",
    "    dataDF['Genres'].iloc[i].strip(\"[]\")\n",
    "    if len(dataDF['Genres'].iloc[i].strip(\"[]\")) < 4:\n",
    "        print(dataDF['Genres'].iloc[i])\n",
    "        dataDF['Genres'].iloc[i] = int(dataDF['Genres'].iloc[i].strip(\"[]\"))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cnt = 0\n",
    "for i in range(len(dataDF['Genres'])):\n",
    "    if type(dataDF['Genres'].iloc[i]) == str:\n",
    "        print(i)\n",
    "        dataDF['Genres'].iloc[i].strip(\"[]\")\n",
    "        tmp = np.array(dataDF['Genres'].iloc[i].strip(\"[]\").split(',')).astype(int)\n",
    "        for j in range(len(tmp)-1):\n",
    "            cnt+=1\n",
    "            dataDF.loc[24999+cnt] = dataDF.iloc[i]\n",
    "            dataDF['Genres'].iloc[-1] = tmp[j+1]\n",
    "        dataDF['Genres'].iloc[i] = tmp[0]\n",
    "with open('FMA_M_list2.pickle', 'wb') as f:\n",
    "    pickle.dump(dataDF, f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# multi-label 학습을 위한 리스트 만들어서 저장\n",
    "import pickle\n",
    "with open('FMA_M_list2.pickle', 'wb') as f:\n",
    "    pickle.dump(dataDF, f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dataDF = pd.read_pickle('FMA_M_list2.pickle')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "y,sr = librosa.load(r\"../fma_medium/152/152330.wav\",duration = 10.01)\n",
    "ps = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ps.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(librosa.power_to_db(ps, ref=np.max), y_axis='mel', x_axis='time')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Mel spectrogram')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cnt=0\n",
    "cntt=0\n",
    "psdict = {}\n",
    "for i in folder[:10]:\n",
    "#     cnt+=1\n",
    "    mp3_list =[]\n",
    "    temp = [mp3_list.extend(k) for i,j,k in walk(r'../fma_medium/'+i+'/') if k[-3:]!='mp3']\n",
    "    for j in mp3_list[2:]:\n",
    "        print(j,cntt)\n",
    "        cntt+=1\n",
    "        y,sr = librosa.load(r\"../fma_medium/\"+i+'/'+j, duration = 10.01)\n",
    "        ps = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "        psdict[j[:-4]] = ps\n",
    "psdictS = pd.Series(psdict.values())\n",
    "psdictDF =  pd.DataFrame(index = psdict.keys())\n",
    "psdictDF = pd.concat([psdictDF.reset_index(),psdictS.reset_index()],axis=1)\n",
    "psdictDF.columns = ['Track', 'index', 'mel_spec']\n",
    "del psdictDF['index']\n",
    "\n",
    "with open('FMA_M_list3.pickle', 'wb') as f:\n",
    "    pickle.dump(psdictDF, f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cnt=0\n",
    "cntt=0\n",
    "psdict = {}\n",
    "for i in folder[10:20]:\n",
    "    cnt+=1\n",
    "    print(cnt)\n",
    "    mp3_list =[]\n",
    "    temp = [mp3_list.extend(k) for i,j,k in walk(r'../fma_medium/'+i+'/') if k[-3:]!='mp3']\n",
    "    for j in mp3_list[2:]:\n",
    "        print(j)\n",
    "#         cntt+=1\n",
    "        y,sr = librosa.load(r\"../fma_medium/\"+i+'/'+j, duration = 10.01)\n",
    "        ps = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "        psdict[j[:-4]] = ps\n",
    "\n",
    "DF = pd.read_pickle('FMA_M_list3.pickle')\n",
    "\n",
    "psdictS = pd.Series(list(psdict.values()))\n",
    "psdictDF =  pd.DataFrame(index = psdict.keys())\n",
    "psdictDF = pd.concat([psdictDF.reset_index(),psdictS.reset_index()],axis=1)\n",
    "psdictDF.columns = ['Track', 'index', 'mel_spec']\n",
    "del psdictDF['index']\n",
    "psdictDF = pd.concat([DF,psdictDF])\n",
    "import pickle\n",
    "with open('FMA_M_list3.pickle', 'wb') as f:\n",
    "    pickle.dump(psdictDF, f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "psdict = {}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cnt=0\n",
    "# cntt=0\n",
    "for i in folder[27:30]:\n",
    "    cnt+=1\n",
    "    print(cnt,'-------------------------------------------------------------------------------------------------------------')\n",
    "    mp3_list =[]\n",
    "    temp = [mp3_list.extend(k) for i,j,k in walk(r'../fma_medium/'+i+'/') if k[-3:]!='mp3']\n",
    "#     mp3_list.remove('105247.wav')\n",
    "#     mp3_list.remove('143992.wav')\n",
    "    for j in mp3_list[2:]:\n",
    "        print(j)\n",
    "#         cntt+=1\n",
    "        y,sr = librosa.load(r\"../fma_medium/\"+i+'/'+j, duration = 10.01)\n",
    "        ps = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "        psdict[j[:-4]] = ps\n",
    "\n",
    "DF = pd.read_pickle('FMA_M_list3.pickle')\n",
    "\n",
    "psdictS = pd.Series(list(psdict.values()))\n",
    "psdictDF =  pd.DataFrame(index = psdict.keys())\n",
    "psdictDF = pd.concat([psdictDF.reset_index(),psdictS.reset_index()],axis=1)\n",
    "psdictDF.columns = ['Track', 'index', 'mel_spec']\n",
    "del psdictDF['index']\n",
    "psdictDF = pd.concat([DF,psdictDF])\n",
    "import pickle\n",
    "with open('FMA_M_list3.pickle', 'wb') as f:\n",
    "    pickle.dump(psdictDF, f)\n",
    "#len(pddictDF) = 4905"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "psdict = {}\n",
    "cnt=0\n",
    "# cntt=0\n",
    "for i in folder[42:50]:\n",
    "    cnt+=1\n",
    "    print(cnt,'-------------------------------------------------------------------------------------------------------------')\n",
    "    mp3_list =[]\n",
    "    temp = [mp3_list.extend(k) for i,j,k in walk(r'../fma_medium/'+i+'/') if k[-3:]!='mp3']\n",
    "#     mp3_list.remove('098571.wav')\n",
    "    for j in mp3_list[2:]:\n",
    "        print(j)\n",
    "#         cntt+=1\n",
    "        y,sr = librosa.load(r\"../fma_medium/\"+i+'/'+j, duration = 10.01)\n",
    "        ps = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "        psdict[j[:-4]] = ps\n",
    "\n",
    "DF = pd.read_pickle('FMA_M_list3.pickle')\n",
    "\n",
    "psdictS = pd.Series(list(psdict.values()))\n",
    "psdictDF =  pd.DataFrame(index = psdict.keys())\n",
    "psdictDF = pd.concat([psdictDF.reset_index(),psdictS.reset_index()],axis=1)\n",
    "psdictDF.columns = ['Track', 'index', 'mel_spec']\n",
    "del psdictDF['index']\n",
    "psdictDF = pd.concat([DF,psdictDF])\n",
    "import pickle\n",
    "with open('FMA_M_list3.pickle', 'wb') as f:\n",
    "    pickle.dump(psdictDF, f)\n",
    "#len(psdictDF) = 7620"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "psdict = {}\n",
    "cnt=0\n",
    "# cntt=0\n",
    "for i in folder[50:60]:\n",
    "    cnt+=1\n",
    "    print(cnt,'-------------------------------------------------------------------------------------------------------------')\n",
    "    mp3_list =[]\n",
    "    temp = [mp3_list.extend(k) for i,j,k in walk(r'../fma_medium/'+i+'/') if k[-3:]!='mp3']\n",
    "#     mp3_list.remove('098571.wav')\n",
    "    for j in mp3_list[2:]:\n",
    "        print(j)\n",
    "#         cntt+=1\n",
    "        y,sr = librosa.load(r\"../fma_medium/\"+i+'/'+j, duration = 10.01)\n",
    "        ps = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "        psdict[j[:-4]] = ps\n",
    "DF = pd.read_pickle('FMA_M_list3.pickle')\n",
    "\n",
    "psdictS = pd.Series(list(psdict.values()))\n",
    "psdictDF =  pd.DataFrame(index = psdict.keys())\n",
    "psdictDF = pd.concat([psdictDF.reset_index(),psdictS.reset_index()],axis=1)\n",
    "psdictDF.columns = ['Track', 'index', 'mel_spec']\n",
    "del psdictDF['index']\n",
    "psdictDF = pd.concat([DF,psdictDF])\n",
    "import pickle\n",
    "with open('FMA_M_list3.pickle', 'wb') as f:\n",
    "    pickle.dump(psdictDF, f)\n",
    "# len(psdictDF) = 9158"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "psdict = {}\n",
    "cnt=0\n",
    "# cntt=0\n",
    "for i in folder[148:]:\n",
    "    cnt+=1\n",
    "    print(cnt,'-------------------------------------------------------------------------------------------------------------')\n",
    "    mp3_list =[]\n",
    "    temp = [mp3_list.extend(k) for i,j,k in walk(r'../fma_medium/'+i+'/') if k[-3:]!='mp3']\n",
    "#     mp3_list.remove('080391.wav')\n",
    "#     mp3_list.remove('126981.wav')\n",
    "#     mp3_list.remove('099134.wav')\n",
    "#     mp3_list.remove('127336.wav')\n",
    "#     mp3_list.remove('133297.wav')\n",
    "#     mp3_list.remove('001486.wav')\n",
    "#     mp3_list.remove('108925.wav')\n",
    "#     mp3_list.remove('005574.wav')\n",
    "#     mp3_list.remove('065753.wav')\n",
    "\n",
    "    for j in mp3_list[2:]:\n",
    "        print(j)\n",
    "#         cntt+=1\n",
    "        y,sr = librosa.load(r\"../fma_medium/\"+i+'/'+j, duration = 10.01)\n",
    "        ps = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "        psdict[j[:-4]] = ps\n",
    "\n",
    "\n",
    "psdictS = pd.Series(list(psdict.values()))\n",
    "psdictDF =  pd.DataFrame(index = psdict.keys())\n",
    "psdictDF = pd.concat([psdictDF.reset_index(),psdictS.reset_index()],axis=1)\n",
    "psdictDF.columns = ['Track', 'index', 'mel_spec']\n",
    "del psdictDF['index']\n",
    "DF = pd.read_pickle('FMA_M_list4.pickle')\n",
    "psdictDF = pd.concat([DF,psdictDF])\n",
    "import pickle\n",
    "with open('FMA_M_list4.pickle', 'wb') as f:\n",
    "    pickle.dump(psdictDF, f)\n",
    "#len(psdictDF) = 10334"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "DF1 = pd.read_pickle('FMA_M_list3.pickle')\n",
    "DF2 = pd.read_pickle('FMA_M_list4.pickle')\n",
    "TotalDF = pd.concat([DF1,DF2])\n",
    "TotalDF = TotalDF.drop_duplicates(['Track'])\n",
    "data_list = pd.read_pickle('FMA_M_list2.pickle')\n",
    "data_list['Track_ID'] = data_list['Track_ID'].astype(str)\n",
    "len(TotalDF), len(data_list)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "psdict = {str(int(k)):v for k,v in zip(TotalDF['Track'],TotalDF['mel_spec'])}\n",
    "tmp = [(i,psdict[i]) for i in list(data_list['Track_ID']) if i in list(psdict.keys())]\n",
    "melDF = pd.DataFrame(tmp)\n",
    "melDF.columns = ['Track','mel_spec']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "droprow = []\n",
    "for i in range(len(data_list['Track_ID'])):\n",
    "    if data_list['Track_ID'].iloc[i] not in list(melDF['Track']):\n",
    "        droprow.append(i)\n",
    "data_list = data_list.reset_index().drop(droprow)\n",
    "del data_list['index']\n",
    "dataset = pd.concat([data_list.reset_index(),melDF['mel_spec']],axis=1)\n",
    "del dataset['index']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('FMA_M_multilabeldataset', 'wb') as f:\n",
    "    pickle.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_pickle('FMA_M_multilabeldataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Genres =  163\n"
     ]
    }
   ],
   "source": [
    "genreslist = pd.read_csv('./fma_metadata/genres.csv')\n",
    "genreslist['title'] = [i.lower() for i in genreslist['title']]\n",
    "print('#Genres = ',len(genreslist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Genres =  97\n",
      "Glove vocab에 포함되지 않는 장르\n",
      "7 old-time / historic\n",
      "12 easy listening\n",
      "13 soul-rnb\n",
      "15 sound effects\n",
      "21 audio collage\n",
      "25 field recordings\n",
      "28 psych-folk\n",
      "30 jazz: vocal\n",
      "33 ambient electronic\n",
      "34 radio art\n",
      "35 loud-rock\n",
      "36 latin america\n",
      "38 free-folk\n",
      "39 noise-rock\n",
      "40 psych-rock\n",
      "42 electro-punk\n",
      "46 no wave\n",
      "48 experimental pop\n",
      "50 reggae - dub\n",
      "55 new wave\n",
      "59 freak-folk\n",
      "60 jazz: out\n",
      "62 alternative hip-hop\n",
      "63 death-metal\n",
      "64 middle east\n",
      "69 space-rock\n",
      "75 spoken weird\n",
      "77 black-metal\n",
      "79 easy listening: vocal\n",
      "81 asia-far east\n",
      "82 n. indian traditional\n",
      "83 south indian traditional\n",
      "88 big band/swing\n",
      "89 british folk\n",
      "93 minimal electronic\n",
      "94 breakcore - hard\n",
      "95 sound poetry\n",
      "96 20th century classical\n",
      "98 talk radio\n",
      "99 north african\n",
      "100 sound collage\n",
      "104 musique concrete\n",
      "106 new age\n",
      "109 chip music\n",
      "112 composed music\n",
      "113 drum & bass\n",
      "117 synth pop\n",
      "119 deep funk\n",
      "120 spoken word\n",
      "122 bigbeat\n",
      "124 radio theater\n",
      "126 rock opera\n",
      "128 chamber music\n",
      "129 choral music\n",
      "132 musical theater\n",
      "134 skweee\n",
      "135 western swing\n",
      "139 sound art\n",
      "140 romany (gypsy)\n",
      "145 abstract hip-hop\n",
      "146 reggae - dancehall\n",
      "148 country & western\n",
      "149 contemporary classical\n",
      "155 nu-jazz\n",
      "156 hip-hop beats\n",
      "157 modern jazz\n"
     ]
    }
   ],
   "source": [
    "# Glove vocab 안에 있는 genre dict\n",
    "wordvec = {}\n",
    "f=open(\"glove.6B.100d.txt\",encoding='utf-8')\n",
    "for i in f:\n",
    "    word = i.split()[0]\n",
    "    if word in list(genreslist['title']):\n",
    "        wordvec[word] = i.split()[1:]\n",
    "print('#Genres = ',len(wordvec.keys()))\n",
    "print('Glove vocab에 포함되지 않는 장르')\n",
    "for i,j in enumerate(genreslist['title']):\n",
    "    if j not in list(wordvec.keys()):\n",
    "        print(i,j)\n",
    "        genreslist = genreslist.drop([i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "genredict = {k:v for k,v in zip(genreslist['genre_id'],genreslist['title'])}\n",
    "tmp = [(i,genredict[i]) for i in list(dataset['Genres']) ]\n",
    "genrewordDF = pd.DataFrame(tmp)\n",
    "genrewordDF.columns = ['Genre','Genreword']\n",
    "dataset = pd.concat([dataset,genrewordDF['Genreword']],axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#FMA_Mediun\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Glove vocab에 포함된 장르의 노래\n",
    "len(dataset.dropna())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = []\n",
    "for i in list(dataset['Genreword']):\n",
    "    if i in list(wordvec.keys()):\n",
    "        tmp.append((i,wordvec[i]))\n",
    "    else:\n",
    "        tmp.append((i,np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpDF = pd.DataFrame(tmp)\n",
    "tmpDF.columns = ['Genreword','Gen2vec']\n",
    "dataset = pd.concat([dataset,tmpDF['Gen2vec']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('FMA_M_multilabeldataset_final', 'wb') as f:\n",
    "    pickle.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "set(dataset['Genreword'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_pickle('FMA_M_multilabeldataset_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordvecDF = pd.DataFrame(wordvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['country', 'international', 'house', 'french', 'europe', 'radio', 'african', 'indian', 'interview', 'rock', 'spanish', 'pacific', 'industrial', 'turkish', 'latin', 'christmas', 'dance', 'holiday', 'metal', 'electronic', 'pop', 'brazilian', 'opera', 'comedy', 'jazz', 'spoken', 'classical', 'blues', 'poetry', 'progressive', 'folk', 'noise', 'experimental', 'celtic', 'symphony', 'soundtrack', 'instrumental', 'jungle', 'garage', 'compilation', 'gospel', 'rap', 'punk', 'balkan', 'surf', 'lounge', 'funk', 'disco', 'drone', 'bollywood', 'hip-hop', 'hardcore', 'novelty', 'singer-songwriter', 'salsa', 'tango', 'bluegrass', 'techno', 'ambient', 'glitch', 'thrash', 'americana', 'sludge', 'avant-garde', 'flamenco', 'polka', 'banter', 'improv', 'goth', 'rockabilly', 'minimalism', 'post-punk', 'klezmer', 'dubstep', 'cumbia', 'fado', 'lo-fi', 'post-rock', 'electroacoustic', 'grindcore', 'breakbeat', 'idm', 'wonky', 'afrobeat', 'krautrock', 'downtempo', 'indie-rock', 'trip-hop', 'shoegaze', 'nerdcore', 'unclassifiable', 'chiptune', 'power-pop', 'be-bop', 'chill-out', 'kid-friendly', 'free-jazz'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8027884404632174"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity([wordvec['hip-hop'],wordvec['rap']])[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcorrword = []\n",
    "for w in wordvec.keys():\n",
    "    for wp in wordvec.keys():\n",
    "        if w==wp:\n",
    "            pass\n",
    "        elif cosine_similarity([wordvec[w],wordvec[wp]])[0][1] > 0.7:\n",
    "            hcorrword.append((w,wp,cosine_similarity([wordvec[w],wordvec[wp]])[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('country', 'europe', 0.7167598346961536),\n",
       " ('french', 'spanish', 0.758211955268014),\n",
       " ('europe', 'country', 0.7167598346961536),\n",
       " ('rock', 'pop', 0.7647685556700637),\n",
       " ('rock', 'punk', 0.7609220634558033),\n",
       " ('spanish', 'french', 0.758211955268014),\n",
       " ('christmas', 'holiday', 0.8736868425460984),\n",
       " ('dance', 'folk', 0.7121563748332252),\n",
       " ('holiday', 'christmas', 0.8736868425460984),\n",
       " ('pop', 'rock', 0.7647685556700637),\n",
       " ('pop', 'rap', 0.7511845693609087),\n",
       " ('pop', 'punk', 0.715317649417896),\n",
       " ('pop', 'hip-hop', 0.7274856864373817),\n",
       " ('opera', 'symphony', 0.7103985305009026),\n",
       " ('jazz', 'blues', 0.7819991899477121),\n",
       " ('jazz', 'folk', 0.7261057802695668),\n",
       " ('blues', 'jazz', 0.7819991899477121),\n",
       " ('folk', 'dance', 0.7121563748332252),\n",
       " ('folk', 'jazz', 0.7261057802695668),\n",
       " ('symphony', 'opera', 0.7103985305009026),\n",
       " ('soundtrack', 'compilation', 0.8114907429053264),\n",
       " ('compilation', 'soundtrack', 0.8114907429053264),\n",
       " ('rap', 'pop', 0.7511845693609087),\n",
       " ('rap', 'hip-hop', 0.8027884404632174),\n",
       " ('punk', 'rock', 0.7609220634558033),\n",
       " ('punk', 'pop', 0.715317649417896),\n",
       " ('punk', 'hardcore', 0.8047592557292904),\n",
       " ('punk', 'techno', 0.7060015581544434),\n",
       " ('punk', 'post-punk', 0.7117344202907443),\n",
       " ('hip-hop', 'pop', 0.7274856864373817),\n",
       " ('hip-hop', 'rap', 0.8027884404632174),\n",
       " ('hardcore', 'punk', 0.8047592557292904),\n",
       " ('tango', 'flamenco', 0.7143408841383327),\n",
       " ('bluegrass', 'rockabilly', 0.7003900152110427),\n",
       " ('techno', 'punk', 0.7060015581544434),\n",
       " ('flamenco', 'tango', 0.7143408841383327),\n",
       " ('rockabilly', 'bluegrass', 0.7003900152110427),\n",
       " ('post-punk', 'punk', 0.7117344202907443),\n",
       " ('post-punk', 'post-rock', 0.7040061773718937),\n",
       " ('post-punk', 'shoegaze', 0.7075334256154001),\n",
       " ('dubstep', 'breakbeat', 0.7239942465676221),\n",
       " ('post-rock', 'post-punk', 0.7040061773718937),\n",
       " ('post-rock', 'indie-rock', 0.7095992748476947),\n",
       " ('post-rock', 'shoegaze', 0.7327012753226352),\n",
       " ('breakbeat', 'dubstep', 0.7239942465676221),\n",
       " ('indie-rock', 'post-rock', 0.7095992748476947),\n",
       " ('indie-rock', 'power-pop', 0.7255111653533615),\n",
       " ('shoegaze', 'post-punk', 0.7075334256154001),\n",
       " ('shoegaze', 'post-rock', 0.7327012753226352),\n",
       " ('power-pop', 'indie-rock', 0.7255111653533615)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hcorrword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rap, indie-rock, post-punk, shoegaze, hardcore"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
