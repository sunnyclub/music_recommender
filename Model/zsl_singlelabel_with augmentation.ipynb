{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.layers import Activation, Dense, Dropout, Conv1D, Conv2D, Flatten, BatchNormalization, ZeroPadding2D, MaxPooling2D, GlobalMaxPooling2D, GlobalAveragePooling1D, AveragePooling2D, Input, Add\n",
    "from keras.models import Sequential\n",
    "from keras import regularizers\n",
    "from keras.optimizers import SGD\n",
    "import keras.backend as K\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import regularizers\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset  = pd.read_pickle('datasetaugment.pickle')\n",
    "for i,j in enumerate(dataset['mel_spec']):\n",
    "    if len(j[0])!=434:\n",
    "         dataset = dataset.drop(i,0)\n",
    "del dataset['index']\n",
    "dataset = dataset.sample(frac=1)\n",
    "dataset = dataset.reset_index()\n",
    "del dataset['index']\n",
    "dataset['Genre'] = dataset['Genre'].replace('Classical','classical')\n",
    "dataset['Genre'] = dataset['Genre'].replace('Country','country')\n",
    "dataset['Genre'] = dataset['Genre'].replace('Electronic','electronic')\n",
    "dataset['Genre'] = dataset['Genre'].replace('Hip-Hop','hip-hop')\n",
    "dataset['Genre'] = dataset['Genre'].replace('Pop','pop')\n",
    "dataset['Genre'] = dataset['Genre'].replace('Rock','rock')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset[dataset['Genre']!='country']\n",
    "test = dataset[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hip-Hop:    207\n",
      "Pop:        226\n",
      "Country:    190\n",
      "Rock:       119\n",
      "Electronic: 147\n",
      "Classical:  111\n"
     ]
    }
   ],
   "source": [
    "print('Hip-Hop:   ',len(test[test['Genre']=='hip-hop']))\n",
    "print('Pop:       ',len(test[test['Genre']=='pop']))\n",
    "print('Country:   ',len(test[test['Genre']=='country']))\n",
    "print('Rock:      ',len(test[test['Genre']=='rock']))\n",
    "print('Electronic:',len(test[test['Genre']=='electronic']))\n",
    "print('Classical: ',len(test[test['Genre']=='classical']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = train['mel_spec'],train['Genre']\n",
    "X_validation, Y_validation = test['mel_spec'],test['Genre']\n",
    "\n",
    "# Reshape for CNN input\n",
    "\n",
    "# X_list = [x.reshape(128, 434,1) for x in X_train]\n",
    "# X1 = np.array(X_list[:3000])\n",
    "# X2 = np.array(X_list[3000:6000])\n",
    "# X3 = np.array(X_list[6000:9000])\n",
    "# X4 = np.array(X_list[9000:12000])\n",
    "# X5 = np.array(X_list[10000:])\n",
    "# X_train = np.concatenate((X1,X2,X3,X4,X5))\n",
    "X_validation = np.array([x.reshape(128, 434, 1) for x in X_validation])\n",
    "\n",
    "# Glove\n",
    "wordvec = {}\n",
    "f=open(\"glove.6B.100d.txt\",encoding='utf-8')\n",
    "classes = ['classical', 'country', 'electronic', 'hip-hop', 'pop', 'rock']\n",
    "for i in f:\n",
    "    word = i.split()[0]\n",
    "    if word in classes:\n",
    "        wordvec[word] = i.split()[1:]\n",
    "\n",
    "        \n",
    "        \n",
    "Y_train = np.array([wordvec[i] for i in Y_train])\n",
    "Y_validation = np.array([wordvec[i] for i in Y_validation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11636, 100)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 125, 431, 24)      408       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 62, 215, 24)       0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 62, 215, 24)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 62, 215, 48)       18480     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 31, 107, 48)       0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 31, 107, 48)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 31, 107, 48)       36912     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_3 (Average (None, 15, 53, 48)        0         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 53, 48)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 38160)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 38160)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              39076864  \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               102500    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 39,235,164\n",
      "Trainable params: 39,235,164\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = Sequential()\n",
    "input_shape=(128, 434, 1)\n",
    "\n",
    "model.add(Conv2D(24, (4, 4), strides=(1, 1), input_shape=input_shape))\n",
    "model.add(AveragePooling2D((2, 2), strides=(2,2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(48, (4, 4), padding=\"same\"))\n",
    "model.add(AveragePooling2D((2, 2), strides=(2,2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(48, (4, 4), padding=\"same\"))\n",
    "model.add(AveragePooling2D((2, 2), strides=(2,2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "epochs = 2\n",
    "batch_size = 5\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with K.tf.device('/gpu:0'):\n",
    "    tb_hist = keras.callbacks.TensorBoard(log_dir='graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=2)\n",
    "#     hist = model.fit(x=X_train, y=Y_train, epochs=epochs, batch_size=batch_size, validation_data= (X_validation, Y_validation), callbacks=[early_stopping, tb_hist]) \n",
    "    hist = model.fit(x=X_train, y=Y_train, epochs=epochs, batch_size=batch_size, callbacks=[early_stopping, tb_hist]) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(hist.history['loss'])\n",
    "# plt.plot(hist.history['val_loss'])\n",
    "plt.plot(hist.history['acc'])\n",
    "# plt.plot(hist.history['val_acc'])\n",
    "plt.legend(['loss', 'acc'])\n",
    "plt.show()\n",
    "\n",
    "score = model.evaluate(x=X_validation, y=Y_validation)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "model.save('ZSL_music_classification.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1016 14:11:17.265329 23632 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\envs\\Review\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1016 14:11:17.497342 23632 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\envs\\Review\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1016 14:11:17.589348 23632 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\envs\\Review\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "W1016 14:11:17.672353 23632 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\envs\\Review\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1016 14:11:17.673352 23632 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\envs\\Review\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1016 14:11:17.744357 23632 deprecation.py:506] From C:\\ProgramData\\Anaconda3\\envs\\Review\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1016 14:11:18.904423 23632 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\envs\\Review\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W1016 14:11:20.228499 23632 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\envs\\Review\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model('ZSL_music_classification.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\Review\\lib\\site-packages\\sklearn\\utils\\validation.py:563: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\Review\\lib\\site-packages\\sklearn\\utils\\validation.py:563: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# validaiton_embeddings = regression_based.predict(X_validation)\n",
    "\n",
    "targets_embeddings = [wordvec['country']]\n",
    "\n",
    "targets_embeddings = np.array(targets_embeddings, dtype=np.float32)\n",
    "\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.metrics import cosine_proximity\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=1)\n",
    "neigh.fit(list(wordvec.values()),[0,1,2,3,4,5])\n",
    "Y_pred_validation = neigh.predict(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.342\n"
     ]
    }
   ],
   "source": [
    "genreclass = {k:v for k,v in zip(list(wordvec.keys()),[0,1,2,3,4,5])}\n",
    "Y_val = [genreclass[i] for i in test['Genre']]\n",
    "cnt = 0\n",
    "for i,j in zip(Y_val, Y_pred_validation):\n",
    "    if i==j:\n",
    "        cnt+=1\n",
    "print('accuracy =', cnt/len(Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(wordvec.values())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_validation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "def cos_sim(A, B):\n",
    "    return dot(A, B)/(norm(A)*norm(B))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Y_pred_validation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#terminal에 텐서보드 실행\n",
    "tensorboard --logdir=\"C:/Users/Yang Saewon/.keras/graph\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 모델 저장\n",
    "model.save('music_genre_classification.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 모델 불러오기\n",
    "model = load_model('music_genre_classification.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "yhat = model.predict_classes(X_test)\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    print('file_name: ' + str(test.index[i]) + ' True: ' + str(np.argmax(Y_test[i])) + ', Predict: ' + str(yhat[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
